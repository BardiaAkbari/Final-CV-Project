{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "r5sAVzdtqU35"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ipLzxSNOKK6",
        "outputId": "719ed0ee-8ef3-4263-b3e3-e9a1d7ff37c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/chenxaoyu/modelnet-normal-resampled?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65G/1.65G [01:17<00:00, 22.9MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/chenxaoyu/modelnet-normal-resampled/versions/1\n",
            "Verified Dataset Root: /root/.cache/kagglehub/datasets/chenxaoyu/modelnet-normal-resampled/versions/1/modelnet40_normal_resampled\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"chenxaoyu/modelnet-normal-resampled\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "dataset_root = \"\"\n",
        "for root, dirs, files in os.walk(path):\n",
        "    if 'airplane' in dirs:\n",
        "        dataset_root = root\n",
        "        break\n",
        "\n",
        "print(f\"Verified Dataset Root: {dataset_root}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSqKAbm3N9Zo",
        "outputId": "62fafe5b-9913-4a4a-d4c8-31e2b7788c5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Final-CV-Project'...\n",
            "remote: Enumerating objects: 198, done.\u001b[K\n",
            "remote: Counting objects: 100% (198/198), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 198 (delta 80), reused 178 (delta 60), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (198/198), 16.09 MiB | 12.07 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/BardiaAkbari/Final-CV-Project.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oacYq0URTck",
        "outputId": "a2d17466-3d55-40f0-972f-be8a0c586fa0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========================================\n",
            "ðŸš€ STARTING TRAINING FOR: pointtransformer38\n",
            "========================================\n",
            "\n",
            "The size of train data is 9843\n",
            "The size of test data is 2468\n",
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/150:   0% 0/2460 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 1/150: 100% 2460/2460 [18:18<00:00,  2.24it/s]\n",
            "Epoch 1: Train Loss 2.4168, Test Loss 1.4886, Train OA 36.80%, Test OA 57.17%, Train mAcc 19.75%, Test mAcc 43.50%\n",
            "ðŸ”¥ New best OA: 57.17%\n",
            "Epoch 2/150:   0% 0/2460 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:627: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "Epoch 2/150:   4% 96/2460 [00:44<17:01,  2.31it/s]"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "os.chdir('/content/Final-CV-Project/Code')\n",
        "\n",
        "model_path = 'models/model_CLS_token.py'\n",
        "if os.path.exists(model_path):\n",
        "    with open(model_path, 'r') as f:\n",
        "        code = f.read()\n",
        "    # if \"import numpy as np\" not in code:\n",
        "    #     code = \"import numpy as np\\n\" + code\n",
        "    # if \".view(B*N_new*K, C)\" in code:\n",
        "    #     code = code.replace(\".view(B*N_new*K, C)\", \".reshape(B*N_new*K, C)\")\n",
        "    with open(model_path, 'w') as f:\n",
        "        f.write(code)\n",
        "\n",
        "models = ['pointtransformer38', 'pointtransformer50']\n",
        "\n",
        "if 'dataset_root' not in locals():\n",
        "    possible_root = \"/root/.cache/kagglehub/datasets/chenxaoyu/modelnet-normal-resampled/versions/1\"\n",
        "    if os.path.exists(possible_root):\n",
        "        dataset_root = possible_root\n",
        "    else:\n",
        "        dataset_root = os.path.abspath(\"data/modelnet40_normal_resampled\")\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"ðŸš€ STARTING TRAINING FOR: {model_name}\")\n",
        "    print(f\"{'='*40}\\n\")\n",
        "\n",
        "    !mkdir -p data\n",
        "    !ln -sfn \"{dataset_root}\" data/modelnet40_normal_resampled\n",
        "\n",
        "    command = (\n",
        "        f\"python train_CLStoken.py \"\n",
        "        f\"--model {model_name} \"\n",
        "        f\"--batch_size 4 \"\n",
        "        f\"--epoch 150 \"\n",
        "        f\"--lr 1e-3 \"\n",
        "        f\"--checkpoint_dir ./checkpoints_{model_name} \"\n",
        "    )\n",
        "\n",
        "    !{command}\n",
        "\n",
        "    print(f\"\\nâœ… FINISHED TRAINING: {model_name}\")\n",
        "\n",
        "    torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYKhIPZc2sIV"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
