{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "r5sAVzdtqU35"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "import os\n",
        "\n",
        "path = kagglehub.dataset_download(\"chenxaoyu/modelnet-normal-resampled\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n",
        "\n",
        "dataset_root = \"\"\n",
        "for root, dirs, files in os.walk(path):\n",
        "    if 'airplane' in dirs:\n",
        "        dataset_root = root\n",
        "        break\n",
        "\n",
        "print(f\"Verified Dataset Root: {dataset_root}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ipLzxSNOKK6",
        "outputId": "9a6874e4-cc5e-435d-a6d5-ed62243cb539"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/chenxaoyu/modelnet-normal-resampled?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65G/1.65G [00:20<00:00, 88.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/chenxaoyu/modelnet-normal-resampled/versions/1\n",
            "Verified Dataset Root: /root/.cache/kagglehub/datasets/chenxaoyu/modelnet-normal-resampled/versions/1/modelnet40_normal_resampled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSqKAbm3N9Zo",
        "outputId": "90fd8f60-2d2b-4384-93da-155c08e10311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Final-CV-Project'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 39 (delta 6), reused 38 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (39/39), 16.03 MiB | 41.36 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/BardiaAkbari/Final-CV-Project.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# 1. CLEANUP MEMORY (Crucial Step!)\n",
        "# We need to free the VRAM held by the crashed process\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "print(\"ðŸ§¹ GPU Memory cleared.\")\n",
        "\n",
        "# 2. Ensure we are in the correct directory\n",
        "os.chdir('/content/Final-CV-Project/Code')\n",
        "\n",
        "# 3. SAFETY PATCH (Ensures model.py is still correct)\n",
        "# (Just in case the file got reverted or changed)\n",
        "model_path = 'models/model.py'\n",
        "if os.path.exists(model_path):\n",
        "    with open(model_path, 'r') as f:\n",
        "        code = f.read()\n",
        "    if \"import numpy as np\" not in code:\n",
        "        code = \"import numpy as np\\n\" + code\n",
        "    if \".view(B*N_new*K, C)\" in code:\n",
        "        code = code.replace(\".view(B*N_new*K, C)\", \".reshape(B*N_new*K, C)\")\n",
        "    with open(model_path, 'w') as f:\n",
        "        f.write(code)\n",
        "\n",
        "# 4. RUN TRAINING WITH LOWER BATCH SIZE\n",
        "models = ['pointtransformer38', 'pointtransformer50']\n",
        "\n",
        "# Ensure dataset root is defined (fallback check)\n",
        "if 'dataset_root' not in locals():\n",
        "    # Attempt to locate it again if the variable was lost in a restart\n",
        "    possible_root = \"/root/.cache/kagglehub/datasets/chenxaoyu/modelnet-normal-resampled/versions/1\"\n",
        "    if os.path.exists(possible_root):\n",
        "        dataset_root = possible_root\n",
        "    else:\n",
        "        # Last resort: check local link\n",
        "        dataset_root = os.path.abspath(\"data/modelnet40_normal_resampled\")\n",
        "\n",
        "for model_name in models:\n",
        "    print(f\"\\n{'='*40}\")\n",
        "    print(f\"ðŸš€ STARTING TRAINING FOR: {model_name}\")\n",
        "    print(f\"{'='*40}\\n\")\n",
        "\n",
        "    # Check data link\n",
        "    !mkdir -p data\n",
        "    !ln -sfn \"{dataset_root}\" data/modelnet40_normal_resampled\n",
        "\n",
        "    # COMMAND CHANGE: batch_size 16 -> 8\n",
        "    command = (\n",
        "        f\"python train.py \"\n",
        "        f\"--model {model_name} \"\n",
        "        f\"--batch_size 8 \"       # <--- REDUCED FROM 16 TO 8\n",
        "        f\"--epoch 150 \"\n",
        "        f\"--lr 1e-3 \"\n",
        "        f\"--checkpoint_dir ./checkpoints_{model_name} \"\n",
        "    )\n",
        "\n",
        "    !{command}\n",
        "\n",
        "    print(f\"\\nâœ… FINISHED TRAINING: {model_name}\")\n",
        "\n",
        "    # Clear memory again between models\n",
        "    torch.cuda.empty_cache()z"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "_oacYq0URTck",
        "outputId": "404d67de-597a-4225-92d7-8ae66684330f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (ipython-input-1568635881.py, line 65)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipython-input-1568635881.py\"\u001b[0;36m, line \u001b[0;32m65\u001b[0m\n\u001b[0;31m    torch.cuda.empty_cache()z\u001b[0m\n\u001b[0m                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    }
  ]
}